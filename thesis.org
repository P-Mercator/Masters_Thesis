#+TITLE: France regional electricity consumption clustering using Generalised Cross Correlation.
#+AUTHOR: Pierre Mercatoris
#+DATE: <2018-05-19 Sat>
#+EMAIL: mercatorispierre@gmail.com

#+PROPERTY: header-args    :eval no-export

#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [12pt]
#+OPTIONS: toc:nil ^:{}
#+EXPORT_EXCLUDE_TAGS: noexport

#+LATEX_HEADER: \usepackage[top=1in, bottom=1.in, left=1in, right=1in]{geometry}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[T1]{fontenc}
#+LATEX_HEADER: \usepackage{fixltx2e}
#+LATEX_HEADER: \usepackage{natbib}
#+LATEX_HEADER: \usepackage{url}
#+LATEX_HEADER: \usepackage{minted}  % for source code
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage{textcomp}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{pdfpages}
#+LATEX_HEADER: \usepackage{setspace}
#+LATEX_HEADER: \usepackage[linktocpage, pdfstartview=FitH, colorlinks, linkcolor=blue, anchorcolor=blue, citecolor=blue,  filecolor=blue,  menucolor=blue,  urlcolor=blue]{hyperref}


* Introduction
** Cluster electricity consumption using GCC
** Clustering time series
* Methodology
** Describe GCC
** Describe data
   The electricity consumption was available at a 30 minutes frequency for each of
   the 12 regions of France from 2013 to 2017. Each year of each region can be
   downloaded from the French transmission operator (Rte) download portal[fn:1].

| Périmètre | Nature              |       Date | Heures | Consommation |
|-----------+---------------------+------------+--------+--------------|
| Grand-Est | Données définitives | 2016-01-01 |  00:00 |         5130 |
| Grand-Est | Données définitives | 2016-01-01 |  00:15 |              |
| Grand-Est | Données définitives | 2016-01-01 |  00:30 |         5130 |
| Grand-Est | Données définitives | 2016-01-01 |  00:45 |              |
| Grand-Est | Données définitives | 2016-01-01 |  01:00 |         5014 |


[fn:1] http://www.rte-france.com/en/eco2mix/eco2mix-telechargement-en]]

* Results
** Data preparation
*** Cleaning
    1. Append all regions and years together
    2. Clean the region names
    3. Format each column to appropriate data type 
    4. Set UTC time to correct summer/winter time changes
    5. Pivot table so that the columns are the regions and the rows are
       consumption values
    6. Resample the date as 30 minutes intervals
    7. Pivot the table again so that we get daily value for each row
    8. 
    9.
    10. 

#+BEGIN_SRC ipython :session :exports none :results silent
  from os.path import join
  import glob
  import pandas as pd

  data_path = "data"

  # Combine all the .xls interruptof each region
  data = pd.concat([
      pd.read_table(
          file, encoding="cp1252", delimiter="\t", engine="python",
          index_col=False).iloc[:-1, :]
      for file in glob.glob(join(data_path, "*.xls"))
  ])

  # Format type of variables
  data["Consommation"] = pd.to_numeric(data["Consommation"], errors='coerce')
  data["Datetime"] = pd.to_datetime(
      (data["Date"] + '_' + data["Heures"]).apply(str), format='%Y-%m-%d_%H:%M')

  # Correct regions names
  data.loc[data['Périmètre'] == 'Auvergne et Rhône-Alpes', 'Périmètre'] = 'Auvergne-Rhône-Alpes'
  data.loc[data['Périmètre'] == 'Bourgogne et Franche Comté', 'Périmètre'] = 'Bourgogne-Franche-Comté'
  data.loc[data['Périmètre'] == 'Alsace, Champagne-Ardenne et Lorraine', 'Périmètre'] = 'Grand-Est'
  data.loc[data['Périmètre'] == 'Nord-Pas-de-Calais et Picardie', 'Périmètre'] = 'Hauts-de-France'
  data.loc[data['Périmètre'] == 'Aquitaine, Limousin et Poitou-Charentes', 'Périmètre'] = 'Nouvelle-Aquitaine'
  data.loc[data['Périmètre'] == 'Languedoc-Roussillon et Midi-Pyrénées', 'Périmètre'] = 'Occitanie'

  # Reshape to row = datetime and column = region, all values are consumption
  consommation = pd.pivot_table(
      data, values='Consommation', index='Datetime', columns=['Périmètre'])
  # Set timezone as it creates problem when changing between daylight saving times.
  consommation = consommation.tz_localize('UTC', ambiguous=False)
  consommation = consommation.resample('30T').mean()
  #+END_SRC

  
  #+BEGIN_SRC ipython :session :ipyfile :exports results :results raw drawer
    import matplotlib.pyplot as plt
    %matplotlib inline

    consommation.loc[:,consommation.mean().sort_values(ascending=False).index].plot(
        alpha=0.7, lw=.1, figsize=(16,9), colormap='Spectral')
    leg = plt.legend(loc='upper right')
    for lh in leg.legendHandles:
        lh.set_linewidth(2)
        lh.set_alpha(1)
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[42]:
  [[file:./obipy-resources/18739LOz.png]]
  :END:

#+BEGIN_SRC ipython :session :exports none :results silent
  import datetime

  consommation["date"] = pd.to_datetime(consommation.index).date
  consommation["time"] = pd.to_datetime(consommation.index).time
  consommation = pd.pivot_table(pd.melt(consommation, id_vars=["date", "time"]),
                                index="date", values="value", columns=["Périmètre", "time"])
  consommation = consommation.loc[datetime.date(2013,1,2):, :]
#+END_SRC


  #+BEGIN_SRC ipython :session :ipyfile :exports results :results raw drawer
    mean_by_time  = consommation.groupby(level=1,  axis=1).mean().reset_index()
    mean_by_time.loc[:,mean_by_time.mean().sort_values(ascending=False).index].plot(
        alpha=0.9, lw=.5, figsize=(20,14), colormap='Spectral')
    leg = plt.legend(loc='upper right')
    for lh in leg.legendHandles:
        lh.set_linewidth(2)
        lh.set_alpha(1)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[45]:
[[file:./obipy-resources/187399XC.png]]
:END:

This resulted in a table of 576 columns (48 x 12 regions) and 1794 rows/days.

|  Périmètre | Auvergne-Rhône-Alpes |          |          |          |          |          |
|       time |             00:00:00 | 00:30:00 | 01:00:00 | 01:30:00 | 02:00:00 | 02:30:00 |
|------------+----------------------+----------+----------+----------+----------+----------|
| 2013-01-02 |               7847.0 |   7674.0 |   7427.0 |   7441.0 |   7467.0 |   7550.0 |
| 2013-01-03 |               9028.0 |   8839.0 |   8544.0 |   8560.0 |   8569.0 |   8667.0 |
| 2013-01-04 |               8982.0 |   8754.0 |   8476.0 |   8480.0 |   8453.0 |   8554.0 |
| 2013-01-05 |               8625.0 |   8465.0 |   8165.0 |   8134.0 |   8087.0 |   8149.0 |
| 2013-01-06 |               8314.0 |   8097.0 |   7814.0 |   7791.0 |   7785.0 |   7842.0 |
*** Transformation
** Distance calculation
*** Selecting k
*** Distance matrix
** Clustering
** Cluster analysis
* Conclusion
